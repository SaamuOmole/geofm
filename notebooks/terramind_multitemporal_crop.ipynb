{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import gdown\n",
    "import terratorch\n",
    "import albumentations\n",
    "import lightning.pytorch as pl\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from terratorch.datamodules import MultiTemporalCropClassificationDataModule\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import tarfile\n",
    "\n",
    "from terratorch.registry import BACKBONE_REGISTRY, TERRATORCH_BACKBONE_REGISTRY, TERRATORCH_DECODER_REGISTRY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "# Downloading the multi-temporal crop classification dataset\n",
    "\n",
    "- Uncomment the cell below to download dataset for the first time\n",
    "- Comment the cell out after first download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_root = \"/Users/samuel.omole/Desktop/repos/geofm_datasets\"\n",
    "# url = \"https://drive.google.com/uc?id=1SycflNslu47yfMg2i_z8FqYkhZQv7JQM\"\n",
    "# archive = dataset_root + \"/multi-temporal-crop-classification-subset.tar.gz\"\n",
    "# extract_dir = dataset_root + \"/multi-temporal-crop-classification-subset\"\n",
    "\n",
    "# # download if missing\n",
    "# if not os.path.isfile(archive):\n",
    "#     gdown.download(url, output=archive, quiet=False)\n",
    "\n",
    "# # extract if not already extracted\n",
    "# if not os.path.isdir(extract_dir):\n",
    "#     with tarfile.open(archive, \"r:gz\") as tar:\n",
    "#         tar.extractall(path=dataset_root)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "# Preparing dataset with TerraTorch datamodule\n",
    "- Now using the `MultiTemporalCropClassificationDataModule` datamodule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## Setting up the datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset_path = Path(\"/Users/samuel.omole/Desktop/repos/geofm_datasets/multi-temporal-crop-classification-subset\")\n",
    "\n",
    "# Adjusted dataset class for this dataset\n",
    "datamodule = MultiTemporalCropClassificationDataModule(\n",
    "    batch_size=8,\n",
    "    num_workers=2,\n",
    "    data_root=dataset_path,\n",
    "    train_transform=[\n",
    "        terratorch.datasets.transforms.FlattenTemporalIntoChannels(),  # Required for temporal data\n",
    "        albumentations.D4(), # Random flips and rotation\n",
    "        albumentations.pytorch.transforms.ToTensorV2(),\n",
    "        terratorch.datasets.transforms.UnflattenTemporalFromChannels(n_timesteps=3), # There are 3 timestamps in the dataset\n",
    "    ],\n",
    "    val_transform=None,  # Using ToTensor() by default\n",
    "    test_transform=None,\n",
    "    expand_temporal_dimension=True,\n",
    "    use_metadata=False, # The crop dataset has metadata for location and time\n",
    "    reduce_zero_label=True, \n",
    ")\n",
    "\n",
    "# Setup train and val datasets\n",
    "datamodule.setup(\"fit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for the dataset means and stds\n",
    "datamodule.means, datamodule.stds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking datasets train split size\n",
    "train_dataset = datamodule.train_dataset\n",
    "len(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking datasets available bands\n",
    "train_dataset.all_band_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking datasets classes\n",
    "train_dataset.class_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## Plotting some training and validation examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a few train samples to visualise\n",
    "for i in range(5):\n",
    "    train_dataset.plot(train_dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking datasets validation split size\n",
    "val_dataset = datamodule.val_dataset\n",
    "len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Also plotting some validation samples\n",
    "for i in range(5):\n",
    "    val_dataset.plot(val_dataset[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking datasets testing split size\n",
    "# required later on when plotting test set predictions\n",
    "datamodule.setup(\"test\")\n",
    "test_dataset = datamodule.test_dataset\n",
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "# Building the TerraMind model and fine-tuning with PyTorch Lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16",
   "metadata": {},
   "source": [
    "## Setting up the trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.seed_everything(0)\n",
    "\n",
    "checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
    "    dirpath=\"../output_multicrop/terramind_small_multicrop/checkpoints/\", # Change as appropriate\n",
    "    mode=\"min\",\n",
    "    monitor=\"val/loss\",\n",
    "    filename=\"best-loss\",\n",
    "    save_weights_only=True,\n",
    ")\n",
    "\n",
    "# Lightning Trainer\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"cpu\", # Use gpu if available \n",
    "    strategy=\"auto\",\n",
    "    devices=1,\n",
    "    precision=\"16-mixed\",\n",
    "    num_nodes=1,\n",
    "    logger=True,\n",
    "    max_epochs=50, # Change as appropriate\n",
    "    log_every_n_steps=1,\n",
    "    callbacks=[checkpoint_callback, pl.callbacks.RichProgressBar()],\n",
    "    default_root_dir=\"../output_multicrop/terramind_small_multicrop/\", # Change as appropriate\n",
    ")\n",
    "\n",
    "# Building the Model\n",
    "model = terratorch.tasks.SemanticSegmentationTask(\n",
    "    model_factory=\"EncoderDecoderFactory\",\n",
    "    model_args={\n",
    "        # TerraMind backbone\n",
    "        \"backbone\": \"terramind_v1_small\",\n",
    "        \"backbone_pretrained\": True,\n",
    "        \"backbone_modalities\": [\"S2L2A\"],\n",
    "        \"backbone_bands\": {\"S2L2A\": [\"BLUE\", \"GREEN\", \"RED\", \"NIR_NARROW\", \"SWIR_1\", \"SWIR_2\"]},\n",
    "\n",
    "        # Apply temporal wrapper (params are passed with prefix backbone_temporal)\n",
    "        \"backbone_use_temporal\": True,\n",
    "        \"backbone_temporal_pooling\": \"concat\",  # Defaults to \"mean\" which also supports flexible input lengths\n",
    "        \"backbone_temporal_n_timestamps\": 3,  # Required for pooling = concat\n",
    "        \n",
    "        # Necks \n",
    "        \"necks\": [\n",
    "            {\n",
    "                \"name\": \"SelectIndices\",\n",
    "                \"indices\": [2, 5, 8, 11] # indices for terramind_v1_tiny, small, and base\n",
    "                # \"indices\": [5, 11, 17, 23] # indices for terramind_v1_large\n",
    "            },\n",
    "            {\n",
    "                \"name\": \"ReshapeTokensToImage\",\n",
    "                \"remove_cls_token\": False,\n",
    "            },\n",
    "            {\"name\": \"LearnedInterpolateToPyramidal\"},            \n",
    "        ],\n",
    "        \n",
    "        # Decoder\n",
    "        \"decoder\": \"UNetDecoder\",\n",
    "        \"decoder_channels\": [512, 256, 128, 64],\n",
    "        \n",
    "        # Head\n",
    "        \"head_dropout\": 0.1,\n",
    "        \"num_classes\": 13,\n",
    "    },\n",
    "    \n",
    "    loss=\"ce\",\n",
    "    lr=1e-4,\n",
    "    optimizer=\"AdamW\",\n",
    "    ignore_index=-1,\n",
    "    freeze_backbone=False,  # Speeds up fine-tuning\n",
    "    freeze_decoder=False,\n",
    "    plot_on_val=True,\n",
    "    class_names=[\"Natural Vegetation\", \"Forest\", \"Corn\", \"Soybeans\", \"Wetlands\", \"Developed / Barren\", \"Open Water\", \"Winter Wheat\", \"Alfalfa\", \"Fallow / Idle Cropland\", \"Cotton\", \"Sorghum\", \"Other\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "trainer.fit(model, datamodule=datamodule)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Evaluate the model performance on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_ckpt_path = \"../output_multicrop/terramind_small_multicrop/checkpoints/best-loss.ckpt\"\n",
    "trainer.test(model, datamodule=datamodule, ckpt_path=best_ckpt_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## Predicting some example test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can use the model for predictions and plotting\n",
    "model = terratorch.tasks.SemanticSegmentationTask.load_from_checkpoint(\n",
    "    best_ckpt_path,\n",
    "    model_factory=model.hparams.model_factory,\n",
    "    model_args=model.hparams.model_args,\n",
    ")\n",
    "\n",
    "test_loader = datamodule.test_dataloader()\n",
    "with torch.no_grad():\n",
    "    batch = next(iter(test_loader))\n",
    "    images = batch[\"image\"]\n",
    "    images = images.to(model.device)\n",
    "    masks = batch[\"mask\"].numpy()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(images)\n",
    "\n",
    "    preds = torch.argmax(outputs.output, dim=1).cpu().numpy()\n",
    "\n",
    "for i in range(5): # 8 is the batch size so set this to <= 8\n",
    "    sample = {\n",
    "        \"image\": batch[\"image\"][i].cpu(),\n",
    "        \"mask\": batch[\"mask\"][i],\n",
    "        \"prediction\": preds[i],\n",
    "    }\n",
    "    test_dataset.plot(sample)\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geofm-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
